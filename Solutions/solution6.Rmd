---
title: "Solution 6"
author: "HeaDS Data Lab"
date: '2024-02-26'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Import necessary libraries:

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(ggplot2)
library(MASS)
```


## Getting the Dataset:

We load the data as described:

```{r message=FALSE, warning=FALSE}
data(birthwt)
?birthwt #display help page
```

Check the class

```{r}
class(birthwt)
```


Make to tibble

```{r}
birthwt <- as_tibble(birthwt)
```


---

## Exploratory Analysis

### The Basics

- Our dataset has 189 observations and 10 variables. 

- Find the description of the column in the help, i.e. `?birthwt`. 

Renaming columns example. **N.B** for the subsequent analysis we use the original names, this chunk is just to show how to rename variables:

```{r  eval=FALSE}
colnames(birthwt) <- c("low", "age", "mother_wt", "race", "smoke", "prev_premie", "ht", "ui", "doctor_visits", "baby_wt")
```

- Check datatypes:

```{r}
str(birthwt)
```

Everything is numeric but the following columns should be factors: low, race, smoke, ptl, ht, ui. We can discuss about ftv, though it has very few different values so it may make more sense to view it as categorical and you can only have discrete numbers of doctor visits. 

```{r}
birthwt <- birthwt %>%
  mutate(low = factor(low),
         race = factor(race),
         smoke = factor(smoke),
         ptl = factor(ptl),
         ht = factor(ht),
         ui = factor(ui),
         ftv = factor(ftv))
```


- The numerical outcome variable is `bwt`, the baby's birthweight. The categorical outcome variable is `low` which indicates whether the birthweight was low. 

- The outcome is not balanced, there are many more observation of normal birthweight:

```{r}
birthwt %>% count(low)
```

- There are no missing values. There are several ways to check, i.e. 

```{r}

# Across the whole tibble
sum(is.na(birthwt))

# Get a NA count for each variable (column)
birthwt %>% summarise(across(everything(), ~ sum(is.na(.))))

```

## Diving into the data

### Numeric variables

The numerical variables are `age` and `lwt`.

- Summary stats:

```{r}
birthwt %>%
  summarise(mean_age = mean(age), 
            median_age = median(age), 
            sd_age = sd(age), 
            min_age = min(age), 
            max_age = max(age),
            mean_wt = mean(lwt), 
            median_wt = median(lwt), 
            sd_wt = sd(lwt), 
            min_wt = min(lwt), 
            max_wt = max(lwt))

# or simply BUT less controlled

summary(birthwt)

```

- boxplots

```{r}
ggplot(birthwt, aes(x=age)) +
  geom_boxplot()
```


```{r}
ggplot(birthwt, aes(x=lwt)) +
  geom_boxplot()
```

- There appear to be many outliers in the mother's weight

- Boxplots split up by outcome

```{r}
ggplot(birthwt, aes(x=age, color = low)) +
  geom_boxplot()
```

```{r}
ggplot(birthwt, aes(x=lwt, color = low)) +
  geom_boxplot()
```

### Categorical variables

- Barplot of smoke. Others analogous. 

```{r}
ggplot(birthwt, aes(x=smoke)) +
  geom_bar()
```

- smoke by outcome

```{r}
ggplot(birthwt, aes(x=smoke, fill = low)) +
  geom_bar()
```


`position ='dodge'` places bars next to each other


```{r}
ggplot(birthwt, aes(x=smoke, fill = low)) +
  geom_bar(position = 'dodge')
```

`position ='fill'` shows the relative percentage of each group 



```{r}
ggplot(birthwt, aes(x=smoke, fill = low)) +
  geom_bar(position = 'fill')
```



```{r}
ggplot(birthwt, aes(x=bwt, fill=smoke)) + 
  geom_density()
```



## Subsetting the data

One example:

```{r}
subset <- birthwt %>%
  #may need to specify that we want dplyr's select function since we also loaded MASS
  dplyr::select(low, bwt, age, lwt, smoke, ht, ftv) %>%
  mutate(ftv=as.factor(ftv))

head(subset)
```

---

## Modelling


### Regression Model 1

We'll make the model on our subset: 

```{r}
model1 <- lm(bwt ~ lwt, data = subset)
```

Inspecting the model object tells us the intercept and slope the model has estimated, as well as the model formula we have used.

```{r}
model1
```

Plot predictor, here mother's weight, VS outcome, baby's weight and insert the estimates for intercept and slope we have obtained from our model.

```{r}
ggplot(subset, aes(x = lwt, y = bwt)) +
  geom_point() +
  geom_abline(slope=4.429, intercept = 2369, color = 'red')
```

There might be a trend in the data but the error is large. See how far most data points are from the regression line. 

```{r}
ggplot(subset, aes(x = lwt, y = bwt)) +
  geom_point() +
  geom_smooth(method = 'lm')
```

The confidence interval is larger in regions with few data points (i.e. at high values of `lwt`). But even where it is relatively tight the error is still huge.

Inspect the model in more detail with `summary()`

```{r}
summary(model1)
```


### Regression Model 2

Remake the model (model2) but this time add an additional explanatory variable to the model in addition to `lwt`

```{r}
#Some examples
model2 <- lm(bwt ~ lwt+ht+smoke, data = subset)
model2 <- lm(bwt ~ lwt+ht, data = subset)
model2 <- lm(bwt ~ lwt+smoke, data = subset)
```

```{r}
summary(model2)
```

Compare Residual standard error and Adjusted R-squared to `model1`. We see slight improvements but not very much.

95% confidence intervals for model2

```{r}
confint(model2)
```

Predict birth weight for a mother weighing 100 lbs, and who is a smoker.
```{r}
newData <- data.frame(lwt=100, smoke=as.factor(1))
newData
predict(model2, newData)
predict(model2, newData, interval="prediction")
```

Output is the estimate for the baby's birth weight along with the 95% confidence interval of this estimate.



### Bonus Exercise - ANOVA

Model with categorical variable as predictor. 

```{r}
model3 <- lm(bwt ~ smoke, data = subset)
```

Now we essentially compare whether the distribution of the outcome, `bwt` differs depending on the level of smoke (0 or 1). Which is why this is a t-test. 

Inspecting the model


```{r}
model3
```

The coefficient of -283 means that the estimate for the mean birthweight decreases by 283 gram when smoke is 1 instead of 0. 

The intercept is the mean estimate for birthweight when smoke is 0. 


```{r}
summary(model3)
```

There seems to be an effect of smoke since the estimate for the coefficient is significant. The intercept is significantly different from 0 which we do not find surprising or noteworthy since babies usually weigh more than 0 gram. 





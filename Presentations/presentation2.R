### II. Working with data in R (R codes for presentation)
### Data Science Lab, University of Copenhagen
### R course, August 2020

### See the files presentation2.html and presentation2.pdf for further explanations. 
### These files are generated by the Markdowm file presentation2.Rmd 

############

#link to question board:
#https://ucph.padlet.org/henrikezschach1/1aka5bg3k7p3qu1q

############
# Load package
library("tidyverse")

############
### Import data

## Often we will work with large datasets that already exist in i.e. an excel sheet or
## a tab separated file. We can easily load that data into R: 
  
# Load a package that can read excel files
library(readxl)



# You can use both relative and absolute paths to point to the data file.
# You can verify where your files are in the 'Files' panel on the lower right.
downloads <- read_excel("Presentations/downloads.xlsx")


# Print first few lines of dataset on screen
downloads
downloads[1:5,]

# Get dimensions of your dataset
dim(downloads)

# How many observations == rows do we have?
nrow(downloads)

# How many data columns are there and what are their types?
summary(downloads)

# How many different servers, i.e. machines are there?
distinct(downloads, machineName)

# How many observations do we have per machine?
count(downloads, machineName)






###############

### Data structures

# Before we continue with tidyverse, lets look at some highly used data structures in R. 
# Want to know what data type or structure you have, try the function class.
class(downloads)

# Both 'str' and 'summary' will you what column types you have. Summary has some extra summary 
# stats on numeric columns.
str(downloads)

# Vectors with characters and numeric values
class(downloads$machineName)
class(downloads$size)






###############


##Exercise A: 10 mins

# 1. Make a new R script
# 2. Read in the climate data which you can find in the Exercises folder using the read_excel function
# 3. Is your data a dataframe or a tibble?

# 4. Have a look at:
# 4.1 How many observations are there?
# 4.2 How many data columns are there and what are their types?
# 4.3 How many different stations are there?
# 4.4 How many observations per station?


###############







### Let's try some tidyverse commands.

# We will use tidyverse syntax in this course. It can look clunky for simple commands, 
# but it is very useful for complex commands

# Tidyverse syntax looks like this:

new_object <-  # the name of the new object you are creating. Can omit if you don't want to save the result
  dataset %>%  # the dataset we are working on
  my_function(arguments...) # the function you want to perform on the dataset

# Often assignment is done on the same line as we name the dataset, i.e.:

new_object <- dataset %>%
  my_function(arguments...) # the function you want to perform on the dataset








###############

### Filtering data (selecting rows): filter

# the filter function allows us to extract rows from a dataset:

downloads %>% 
  filter(time > 1000) # processed from left to right

# The result of our filter command appears in the console. However, it is not saved in memory! 
# If we want to continue to work with the result of our command, we need to assign it to an object by giving it a name:


large_downloads <- downloads %>% 
  filter(time > 1000)

# This time a new object named 'large_downloads' has appeared in our environment!

# What is the type of this object?
class(large_downloads)

# Lets create a dataframe that only contains downloads with a size >0
downloads3 <- downloads %>% 
  filter(size > 0)

# view the newly generated object:
downloads3 # print the first lines in console
View(downloads3) # view the whole data in a new tab
head(downloads3) # "head" of dataset 


# what are the unique machine names in downloads3?
distinct(downloads3, machineName)


# Filtering with two conditions:
# Datalines from kermit, and with size greater than 2000000 bytes are kept.
d4 <- downloads3 %>% 
  filter(machineName == "kermit" & size > 2000000)


# what if you want to include multiple options for a column, i.e. several different machines?
d4 <- downloads3 %>% 
  filter(machineName %in% c("kermit","pluto"), size > 2000000)


# also have a look at the help:
?filter

# There are several packages that have a filter function. 
# We specify that we want the help for the function 'filter' from the dplyr package:
?dplyr::filter






#############

### Selecting variables (columns): select

# Similar to filter, but observe that this works on columns instead!

# Create a tibble without the date variable: negative selection
without_date <- downloads3 %>% 
  select(-date)

# Positive selection: Include these columns:
downloads4 <- downloads3 %>% select(machineName, size, time)
downloads4





#############

#Exercise B: 5-10 mins

# On the climate dataset, select:
# 1. all rows from the station in Oxford
# 2. all rows from the station in Oxford when there were at least 100 hours of sunlight
# 3. all rows from the stations in Oxford and Camborne when there were at least 100 hours of sunlight 
# 4. a subset that only contains the station, year and rain columns

###############





### Transformations of data

## We can add new columns to our dataframe or tibble with the command 'mutate'

# check the currently existing columns:
str(downloads4)

# Note that this command does the exact same but in tidyverse syntax:
downloads4 %>% str()

# The reason we sometimes do not use tidyverse syntax is brevity. 




# Create a column named 'logSize' which is the logarithm of the size column:
downloads4 <- downloads4 %>% 
  mutate(logSize = log10(size))

# Remember to re-assign with <-, otherwise your new column is going nowhere!
# Check the new column has appeared
str(downloads4)

# Notice that in the above example our input and output dataframe are the same (downloads4). 


# We can also create several columns within the same mutate command, just separate them by comma:
downloads4 <- downloads4 %>% 
  mutate(logSize = log10(size), speed = size / time)

# A useful operator for generating new columns is "ifelse"
# It generates a vector based on whether a condition is true or not:
downloads4 <- downloads4 %>% 
  mutate(slow = ifelse(speed < 150, "Yes", "No"))

downloads4

?mutate






###########

### Counting, tabulation of categorical variables: count

# We already used count above to get the number of lines for each machine: 
downloads4 %>% count(machineName)

# We can also add conditional statements :
# Number of observations which have/have not size larger than 5000
downloads4 %>% count(size>5000)

# Number of observations for each combiation of machine name and the *slow* variable.
downloads4 %>% count(machineName, slow)

# Total number of observations in the current dataset: Call count without any arguments
downloads4 %>% count()






##########

#Exercise C: 10 mins

# 1. To the climate dataset, add:
# 1.1 A column that states the amount of hours with no sunshine for each month. A month has on 
# average 730 hours, you can use the same amount of hours of all of them.
# 1.2. A column the says whether the weather this month was good. We consider a month to be good if it had at least 
# 50 hours of sunlight and less than 100 mm of rain. Otherwise the weather was bad.

# 2. Count the number of: 
# 2.1 Months per station that did not have any days with air frost (so two conditions)
# 2.2 Months with good weather per station (use the column you made in 1.2). What's the place with 
# the best weather in England? 

###########






## Sorting data: arrange

# Sort after size
downloads4 %>% arrange(size)

# Sort according to download size in descending order
downloads4 %>% arrange(desc(size))

# Sort after machine name and then according to download size in descending order
downloads4 %>% arrange(machineName, desc(size))

# Note that we have not re-assigned the results to anywhere, they are not saved!




#########

### Grouping: group_by

## 'group_by' is used to create groupings inside a dataframe or tibble:
  
# Group according to machine
downloads4 %>% group_by(machineName)

# Group according to machine and slow
downloads4 %>% group_by(machineName, slow)

# By itself, group_by does nothing, we still get the same dataset. But we can use it in combination
# with other commands (more below).





###########

### Summary statistics, revisited: summarize

# We already saw how to calculate summary stats on a column: 
mean(downloads4$size)
max(downloads4$size)

# But 'tis not the tidyverse way! So let's pipe the data (downloads4) into the summarize function. 
downloads4 %>% 
  summarise(mean(size))

# We can also get means for all columns with summarise_all. Note that non-numeric columns give an error.
downloads4 %>% 
  summarise_all(mean)

# The result of summarize is a tibble or dataframe that contains the summary stats we asked for:
sum_res <- downloads4 %>% 
  summarise(mean(size))
class(sum_res)
sum_res

# We can use assignment inside summarize to name the columns in the resulting dataframe:
sum_res2 <- downloads4 %>% 
  summarise(avg_size = mean(size))
class(sum_res2)
sum_res2

# Compare sum_res and sum_res2. You will note the (only) column of sum_res is named mean(size)  
# This is annoying when you later want to call upon the column by name! Better to rename it.

# We can also get several summary stats at the same time:
# Note that indentation doesn't matter to R.
sum_res3 <- downloads4 %>% 
  summarise(avg = mean(size), 
            med = median(size), 
            stdev = sd(size), 
            total = sum(size))
class(sum_res3)
sum_res3

# Now this is where the group_by fun comes in! We use it to generate groupings in our dataframe/tibble
# which are then respected by the next functions we pipe our data into! 


# Group after machine name and make summaries for each machine
downloads4 %>%
  group_by(machineName) %>%
  summarise(avg = mean(size),
            med = median(size),
            stdev = sd(size),
            total = sum(size),
            n = n())

# We can also group_by a combination of features:
downloads4 %>%
  group_by(machineName, slow) %>%
  summarise(avg = mean(size),
            med = median(size),
            stdev = sd(size),
            total = sum(size),
            n = n())


# We can also get several statistics for several variables: Here mean and standard deviation
downloads4 %>%
  summarize_at(c("time", "size"), list(ave=mean,stdev=sd))



# Note that R is tolerant of BE/AE spelling differences. 'summarise' and 'summarize' are the same 
# function, likewise with 'color' and 'colour'.





##########

### The pipe operator: %>%

# One operator to rule them all! Many commands can be combined with the pipe operator
# Note: The input dataframe is always at the beginning of the sequence

downloads %>% 
  filter(size>0) %>% # Subset of data
  group_by(machineName) %>% # Grouping 
  summarize(avg = mean(size)) %>% # Compute mean
  arrange(avg) # Sort after mean

# Remember to re-assign if you want to keep using the object you created:

size_sorted_df <- downloads %>% 
  filter(size>0) %>% # Subset of data
  group_by(machineName) %>% # Grouping 
  summarize(avg = mean(size)) %>% # Compute mean
  arrange(avg) # Sort after mean

##########





## lunch

## Exercise: exercise2.html 




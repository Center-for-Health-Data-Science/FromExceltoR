### II. Working with data in R (R codes for presentation)
### Data Science Lab, University of Copenhagen
### R course, August 2020

### See the files presentation2.html and presentation2.pdf for further explanations. 
### These files are generated by the Markdowm file presentation2.Rmd 


#############

### Set working directory 

# show current working directory
getwd()

# show folders in cwd
list.dirs(path = ".", recursive = FALSE)

# relative path
setwd('./Presentations')

# go one step back in the directory
setwd('..')

# absolute path
setwd("~/Documents/work/Projects/FromExceltoR_2021/Presentations")

############
### Tidyverse package 
#install.packages('tidyverse')

# Load package
library("tidyverse")

############

### Import data
  
# Load a package that can read excel files
library(readxl)

# This command is generated via the Import data facility
downloads <- read_excel("downloads.xlsx")
downloads = read_excel("downloads.xlsx")
# see that you can assign variables with either '<-' or '='?
# choose a style and stick to it

# Print first lines of dataset on screen
downloads
downloads[1:5,]

# Get dimensions of your dataset
dim(downloads)

#############

### Extracting variables, simple summary statistics

# Extract time variable by use of $ syntax
time_vector = downloads$time

# Print first 40 elements on screen
time_vector[1:40]

# Simple summary statistics
length(time_vector)
mean(time_vector)
sd(time_vector)
median(time_vector)
min(time_vector)

###############

### Let's try some tidyverse commands.

###############

### Filtering data (selecting rows): filter
  
# see only datalines with time variable >1000
filter(downloads, time > 1000)
# great about tidyverse: write code the way you think
filter(downloads, time > 1000) # processed from inside to outside
downloads %>% filter(time > 1000) # processed from left to right

# my style: when assigning and doing multiple operations, use pipe operator
# also when it helps readability
# otherwise write as little as possible

# Only datalines with size variable >0
downloads2 = downloads %>% filter(size > 0)

# view data
downloads2 # print the first lines in console
View(downloads2) # view the whole data in a new tab

# what are the unique machine names in downloads2?
distinct(downloads2, machineName)

# Datalines from kermit, and with size greater than 2000000 bytes are kept.
downloads2 %>% 
  filter(machineName == "kermit" & size > 2000000)

# other conditional operators can be found in the first presentation!
# or just google it

?dplyr::filter

# what if you want to filter multiple arguments in a variable?
downloads2 %>% 
  filter(machineName %in% c("kermit","pluto"), size > 2000000)

#############

### Selecting variables (columns): select

# Without the date variable
select(downloads2, -date)

# Only include the three mentioned variable names
downloads3 = downloads2 %>% select(machineName, size, time)
downloads3

###############

### Transformations of data

# New variables included in dataset
downloads3 = downloads3 %>% 
  mutate(speed = size / time, logSize = log10(size))
downloads3
downloads3 = downloads3 %>% 
  mutate(slow = ifelse(speed < 150, "Yes", "No"))
downloads3

?mutate
###########

### Counting, tabulation of categorical variables: count

# Total number of observations in the current dataset
count(downloads3)

# Number of observations from each machine
count(downloads3, machineName)

# Number of observations which have/have not size larger than 5000
count(downloads3, size>5000)

# Number of observations for each combiation of machine name and the *slow* variable.
count(downloads3, machineName, slow)

##########

## Sorting data: arrange

# Sort after size
arrange(downloads3, size)

# Sort according to download size in descending order
arrange(downloads3, desc(size))

# Sort after machine name and then according to download size in descending order
arrange(downloads3, machineName, desc(size))

#########

### Grouping: group_by
  
# Group according to machine
group_by(downloads3, machineName)

# Group according to machine and slow
group_by(downloads3, machineName, slow)

###########

### Summary statistics, revisited: summarize

# Method from above  
mean(downloads3$size)
max(downloads3$size)

# Group after machine name and make summaries for each machine
downloads3 %>%
  group_by(machineName) %>%
  summarise(avg = mean(size),
            med = median(size),
            stdev = sd(size),
            total = sum(size),
            n = n())


# Group after machine name and slow variable, and make summaries for each combination
downloads.grp2 = downloads3 %>% 
  group_by(machineName, slow)

summarize(downloads.grp2, 
          avg = mean(size),
          med = median(size),
          stdev = sd(size),
          total = sum(size),
          n = n())

# Mean and standard deviation for several variables: 
summarize_at(downloads.grp2, c("time", "size"), list(ave=mean,stdev=sd))

##########

### The pipe operator: %>%

# Many commands combined with the pipe operator
" see that the variables for functions change, 
as the dataframe stands now at the beginning of the sequence "
downloads %>% 
  filter(size>0) %>% # Subset of data
  group_by(machineName) %>% # Grouping 
  summarize(avg = mean(size)) %>% # Compute mean
  arrange(avg) # Sort after mean


---
title: "II. Working with data in R (presentation)"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Tidyverse package 

The tidyverse is a collection of R packages which, among other things, facilitate data handling and data transformation in R. See <https://www.tidyverse.org/> for details. 

We must install and load the R package **tidyverse** before we have access to the functions. 

* Install package: One option is to go via the _Packages_ tab of the lower right panel: *Packages* &#8594; *Install* &#8594; write `tidyverse` in the field called _Packages_. This only has to be done once. Otherwise use the `install.packages` function as shown here:  
```{r, message=FALSE, eval=FALSE}
install.packages("tidyverse", repos = "https://mirrors.dotsrc.org/cran/")
```

* Load package: Use the `library` command. This has to be done in every R-session where you use the package. 
```{r, message=FALSE}
library(tidyverse)
```

---

## Import data

Data from Excel files can be imported via the _Import Dataset_ facility. You may get the message that the package **readxl** should be installed. If so, then install it as explained for **tidyverse** above. 

* In the _Environment_ tab in the upper right panel, find _Import Dataset_ and choose _From Excel_ in the dropdown menu.

* A new window opens. Browse for the relevant Excel file; then a preview of the dataset is shown. Check that it looks OK, and click _Import_. 

* Three things happened: Three lines of code were generated (and executed) in the Console, a new dataset now appears in the Environment window, and the dataset is shown in the top left window. Check again that it looks OK. 

* Copy the first two lines of code into your R script (or into an R chunk in your Markdown document), but delete the line starting with `View` and write instead the name of the dataset, here **downloads**. Then the first 10 lines of the data set are printed. 

```{r}
library(readxl)
downloads <- read_excel("downloads.xlsx")
downloads
```

R has stored the data in a so-called _tibble_, a type of data frame. 
Rows are referred to as *observations* or *data lines*, columns as *variables*.
The data rows appear in the order as in the Excel file.

A slight digression: If data are saved in a csv file (comma separated values), possibly generated via an Excel sheet, 
then data can be read with the read_csv function. For example, if the data file is called `mydata.csv` and values are separated with commas, then the command 
```{r, echo=TRUE, eval=FALSE}
mydata <- read.csv("mydata.csv", sep=",")
```
creates a data frame in R with the data. The dataframe is _not_ a tibble and some of the commands below would not work for such a data frame. However, you can easily cast dataframes into tibbles, see presentation1.Rmd . 


---

## About the data

The dataset is from Boston University and is about www data transfers from November 1994 to May 1995, see <http://ita.ee.lbl.gov/html/contrib/BU-Web-Client.html>.


* It has 147,035 data lines and 6 variables

* _size_ is the download size in bytes, and _time_ is the download time in seconds.

---

## Filtering data (selecting rows): `filter`

The `filter` function is used to make sub-datasets where only certain data lines (rows) are maintained. It's described with _logical expressions_ which lines should be kept in the dataset.

Say that we only want observations with download time larger than 1000 seconds; there happens to be eight such observations: 

```{r}
downloads %>% 
  filter(time > 1000)
```

Or say that only want observations with strictly positive download size:

```{r}
downloads3 <- downloads %>%
  filter(size > 0)
```

Notice that this result is assigned to **downloads3**. It has 36,708 data lines. The original data called **downloads** still exists with 147,035 data lines.

Filtering requires *logical predicates*. These are expressions in terms of columns, which evaluate to either `TRUE` or `FALSE` for each row. Logical expressions can be combined with logical operations.

* Comparisons: ` == `, ` != `, ` < `, ` > `, ` <= `, ` >= `, ` %in% `, ` is.na `

* Logical operations: `!` (not), `|` (or), `&` (and). A comma can be used instead of `&`

Here comes two sub-datasets:


```{r}
# Rows from kermit, and with size greater than 200000 bytes are kept.
downloads3 %>% filter(machineName == "kermit", size > 200000)

# Rows NOT from kermit, and with size greater than 200000 bytes are kept.
downloads3 %>% filter(machineName != "kermit" & size > 200000)
```

A helpful function to know which machine names are valid can be:

```{r}
# get unique machineName values in downloads3
distinct(downloads3, machineName)
```

And if you are looking for multiple values for a given variable:

```{r}
downloads3 %>% filter(machineName %in% c("kermit","pluto"), size > 2000000)
```

---

## Selecting columns: `select`

Sometimes, datasets have many columns of variables of which only some are relevant for the analysis. Columns can be selected or skipped with the `select` function.

```{r}
# Only include the three mentioned variable names
downloads4 <- downloads3 %>%
  select(machineName, size, time)
downloads4
```

Notice that we have made a new dataframe, **downloads4** with only three variables. 


---

## Transformations of data

Transformations of existing variables in the data set can be computed and included in the data set with the `mutate` function. 

We first compute two new variables, download speed (**speed**) and the logarithm of the download size (**logSize**):

```{r}
downloads4 <- downloads4 %>%
  mutate(speed = size / time, logSize = log10(size))
downloads4
```

We then make a new categorial variable, **slow**, which is "Yes" is speed < 150 and "No" otherwise

```{r}
downloads4 <- downloads4 %>%
  mutate(slow = ifelse(speed < 150, "Yes", "No"))
downloads4
```

---

## Counting, tabulation of categorical variables: `count`

The `count` function is useful for counting data datalines, possibly according to certain criteria or for the different levels of categorical values.



```{r}
# Total number of observations in the current dataset
downloads4 %>% count()

# Number of observations from each machine
downloads4 %>% count(machineName)

# Number of observations which have/have not size larger than 5000
downloads4 %>% count(size>5000)
```

---

## Sorting data: `arrange`

The `arrange` function can be used to sort the data according to one or more columns.

Let's sort the data according to download size (ascending order). The first lines of the sorted data set is printed on-screen, but the dataset **downloads4** has *not* been changed.

```{r}
downloads4 %>% arrange(size)
```

Two different examples:

```{r}
# According to download size in descending order
downloads4 %>% arrange(desc(size))

# After machine name and then according to download size in descending order
downloads4 %>% arrange(machineName, desc(size))
```

---

## Grouping: `group_by`

We can group the dataset by one or more categorical variables with `group_by`. The dataset is not changed as such, but - as we will see - grouping can be useful for computation of summary statistics and graphics. 

Here we group after machine name (first) _and_ the slow variable (second). The only way we can see it at this point is in the second line in the output (`# Groups:`):

```{r}
# Group according to machine
downloads4 %>% group_by(machineName)

# Group according to machine and slow
downloads4 %>% group_by(machineName, slow)
```

---

## Summary statistics, revisited: `summarize`

Recall how we could compute summary statistics for a single variable in a dataset, e.g.

```{r}
mean(downloads4$size)
max(downloads4$size)
```

With `summarize` we can compute summary statistics for a variable for each level of a grouping variable or for each combination of several grouping variables. 

First, a bunch of summaries for the size variable for each machine name, where we give explicit names for the new variables:

```{r}
downloads4 %>%
  group_by(machineName) %>%
  summarise(avg = mean(size),
            med = median(size),
            stdev = sd(size),
            total = sum(size),
            n = n())
```

Second, the same thing but for each combination of machine name and the slow variable:

```{r}
downloads4 %>% 
  group_by(machineName, slow) %>%
  summarize(avg = mean(size),
            med = median(size),
            stdev = sd(size),
            total = sum(size),
            n = n())
```



The datasets with summaries can be saved as datasets themselves, for example to be used as the basis for certain graphs. 

---

## The pipe operator: `%>%`

Two or more function calls can be evaluated sequentially using the so-called pipe operator, `%>%`. Nesting of function calls becomes more readable, and intermediate assignments are avoided.

Let's try it to do a bunch of things in one go, starting with the original dataset:

```{r}
downloads %>% 
  filter(size>0) %>% # Subset of data
  group_by(machineName) %>% # Grouping 
  summarize(avg = mean(size)) %>% # Compute mean
  arrange(avg) # Sort after mean
```

---


## More functions: `relocate, rename, pull & join`

Below are three useful functions for column manipulation,  `relocate`, `rename` and `pull`:

```{r}
# relocate (move one or more columns):
downloads %>% relocate(time, .before = size)

# rename (rename one column):
downloads %>% rename(year.month=month)

# pull out one column, equivalent to using $:
downloads %>% pull(machineName) %>% head()
```


---

Below is an example of how to use the family of `_join` function included in tidyverse.
They are useful for combining two (or more) datasets, even if the sets only contain partial/subset of information.

```{r}

# Join tibbles with subsets of information together:

# machineName and power rank
dowloads5 <- tibble(machineName=c("cs18","piglet","tweetie","kermit", "pluto"),
                    powerRank=c(2,4,1,3,5))

# machineName and location of machine
dowloads6 <- tibble(machineName=c("cs18","tweetie","kermit","skeeter"),
                    location=c("China", "USA", "Germany", "Japan"))

# all machineNames from tibble on the left are kept
left_join(dowloads5, dowloads6)

# all machineNames from tibble on the right are kept
right_join(dowloads5, dowloads6)

# only machineNames in both left and right tibble are kept 
inner_join(dowloads5, dowloads6)

# all machineNames, from both tibbles are kept
full_join(dowloads5, dowloads6)


```

